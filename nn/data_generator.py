"""å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆå‡¦ç†ã€‚
"""
import glob
import os
import random
from typing import List, NoReturn
import numpy as np
from board.go_board import GoBoard
from board.stone import Stone
from nn.feature import generate_input_planes, generate_target_data, \
    generate_rl_target_data
from sgf.reader import SGFReader
from learning_param import BATCH_SIZE, DATA_SET_SIZE

import time, datetime#################


def _save_data(save_file_path: str, input_data: np.ndarray, policy_data: np.ndarray,\
    value_data: np.ndarray, kifu_counter: int) -> NoReturn:
    """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’npzãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦å‡ºåŠ›ã™ã‚‹ã€‚

    Args:
        save_file_path (str): ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€‚
        input_data (np.ndarray): å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã€‚
        policy_data (np.ndarray): Policyã®ãƒ‡ãƒ¼ã‚¿ã€‚
        value_data (np.ndarray): Valueã®ãƒ‡ãƒ¼ã‚¿
        kifu_counter (int): ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã‚ã‚‹æ£‹è­œãƒ‡ãƒ¼ã‚¿ã®å€‹æ•°ã€‚
    """
    save_data = {
        "input": np.array(input_data[0:DATA_SET_SIZE]),
        "policy": np.array(policy_data[0:DATA_SET_SIZE]),
        "value": np.array(value_data[0:DATA_SET_SIZE], dtype=np.int32),
        "kifu_count": np.array(kifu_counter)
    }
    np.savez_compressed(save_file_path, **save_data)

# pylint: disable=R0914
def generate_supervised_learning_data(program_dir: str, kifu_dir: str, \
    board_size: int=9) -> NoReturn:
    """æ•™å¸«ã‚ã‚Šå­¦ç¿’ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ä¿å­˜ã™ã‚‹ã€‚

    Args:
        program_dir (str): ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ãƒ›ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã€‚
        kifu_dir (str): SGFãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ ¼ç´ã—ã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã€‚
        board_size (int, optional): ç¢ç›¤ã®ã‚µã‚¤ã‚º. Defaults to 9.
    """
    dt_watch = datetime.datetime.now()
    print(f"ðŸ¾generate_supervised_learning_data {dt_watch}ðŸ¾")############

    board = GoBoard(board_size=board_size)

    input_data = []
    policy_data = []
    value_data = []

    kifu_counter = 1
    data_counter = 0

    kifu_num = len(glob.glob(os.path.join(kifu_dir, "*.sgf")))######
    print(f"kifu_num: {kifu_num}")#############

    for kifu_path in sorted(glob.glob(os.path.join(kifu_dir, "*.sgf"))):
        board.clear()
        sgf = SGFReader(kifu_path, board_size)
        color = Stone.BLACK
        value_label = sgf.get_value_label()

        for pos in sgf.get_moves():
            for sym in range(8):
                input_data.append(generate_input_planes(board, color, sym))
                policy_data.append(generate_target_data(board, pos, sym))
                value_data.append(value_label)
            board.put_stone(pos, color)
            color = Stone.get_opponent_color(color)
            # Valueã®ãƒ©ãƒ™ãƒ«ã‚’å…¥ã‚Œæ›¿ãˆã‚‹ã€‚
            value_label = 2 - value_label

        if len(value_data) >= DATA_SET_SIZE:
            _save_data(os.path.join(program_dir, "data", f"sl_data_{data_counter}"), \
                input_data, policy_data, value_data, kifu_counter)
            input_data = input_data[DATA_SET_SIZE:]
            policy_data = policy_data[DATA_SET_SIZE:]
            value_data = value_data[DATA_SET_SIZE:]
            kifu_counter = 1
            data_counter += 1

            print(f"""\
    saved: sl_data_{data_counter}.npz ({datetime.datetime.now() - dt_watch})
    from: {kifu_path} / {kifu_num}\
""")#####################
            dt_watch = datetime.datetime.now()

        kifu_counter += 1
    print("qwer")

    # ç«¯æ•°ã®å‡ºåŠ›
    n_batches = len(value_data) // BATCH_SIZE
    if n_batches > 0:
        _save_data(os.path.join(program_dir, "data", f"sl_data_{data_counter}"), \
            input_data[0:n_batches*BATCH_SIZE], policy_data[0:n_batches*BATCH_SIZE], \
            value_data[0:n_batches*BATCH_SIZE], kifu_counter)


def generate_reinforcement_learning_data(program_dir: str, kifu_dir_list: List[str], \
    board_size: int=9) -> NoReturn:
    """å¼·åŒ–å­¦ç¿’ã§ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã€ä¿å­˜ã™ã‚‹ã€‚

    Args:
        program_dir (str): ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ãƒ›ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€‚
        kifu_dir_list (List[str]): æ£‹è­œãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆã€‚
        board_size (int, optional): ç¢ç›¤ã®å¤§ãã•ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯9ã€‚
    """
    dt_watch = datetime.datetime.now()
    print(f"ðŸ¾generate_reinforcement_learning_data {dt_watch}ðŸ¾")##################

    board = GoBoard(board_size=board_size)

    input_data = []
    policy_data = []
    value_data = []

    kifu_counter = 1
    data_counter = 0

    kifu_list = []
    for kifu_dir in kifu_dir_list:
        # kifu_list.extend(glob.glob(os.path.join(kifu_dir, "*", "*.sgf"))) # natukazeã®æ£‹è­œã®ãƒ•ã‚©ãƒ«ãƒ€å½¢å¼ã«åˆã†ã‚ˆã†ã«ã—ãŸ
        kifu_list.extend(glob.glob(os.path.join(kifu_dir, "*.sgf")))
    random.shuffle(kifu_list)

    for kifu_path in kifu_list:
        board.clear()
        sgf = SGFReader(kifu_path, board_size)
        color = Stone.BLACK
        value_label = sgf.get_value_label()
        target_index = sorted(np.random.permutation(np.arange(sgf.get_n_moves()))[:8]) # ç·æ‰‹æ•°ä»¥ä¸‹ã®æ•°ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã§ï¼˜å€‹é¸ã‚“ã§é¸ã‚“ã ã®ã‚’ã‚½ãƒ¼ãƒˆ
        sym_index_list = np.random.permutation(np.arange(8))
        sym_index = 0
        #target_index = np.random.permutation(np.arange(sgf.get_n_moves()))[:1]
        #sym = np.random.permutation(np.arange(8))[0]
        for i, pos in enumerate(sgf.get_moves()):
            if i in target_index:
                sym = sym_index_list[sym_index]
                input_data.append(generate_input_planes(board, color, sym))
                policy_data.append(generate_rl_target_data(board, sgf.get_comment(i), sym))
                value_data.append(value_label)
                sym_index += 1
            board.put_stone(pos, color)
            color = Stone.get_opponent_color(color)
            value_label = 2 - value_label

        if len(value_data) >= DATA_SET_SIZE:
            _save_data(os.path.join(program_dir, "data", f"rl_data_{data_counter}"), \
                input_data, policy_data, value_data, kifu_counter)
            input_data = input_data[DATA_SET_SIZE:]
            policy_data = policy_data[DATA_SET_SIZE:]
            value_data = value_data[DATA_SET_SIZE:]
            kifu_counter = 1
            data_counter += 1

        kifu_counter += 1

    # ç«¯æ•°ã®å‡ºåŠ›
    n_batches = len(value_data) // BATCH_SIZE
    if n_batches > 0:
        _save_data(os.path.join(program_dir, "data", f"rl_data_{data_counter}"), \
            input_data[0:n_batches*BATCH_SIZE], policy_data[0:n_batches*BATCH_SIZE], \
            value_data[0:n_batches*BATCH_SIZE], kifu_counter)

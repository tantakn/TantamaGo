"""æ·±å±¤å­¦ç¿’ã«é–¢ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã€‚
"""
from typing import NoReturn, Dict, List, Tuple
import time
import datetime
import torch
import numpy as np

from common.print_console import print_err
from nn.network.dual_net import DualNet


def get_torch_device(use_gpu: bool) -> torch.device:
    """torch.deviceã‚’å–å¾—ã™ã‚‹ã€‚

    Args:
        use_gpu (bool): GPUä½¿ç”¨ãƒ•ãƒ©ã‚°ã€‚

    Returns:
        torch.device: ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã€‚
    """
    if use_gpu:
        torch.cuda.set_device(0)
        return torch.device("cuda")
    return torch.device("cpu")


def _calculate_losses(loss: Dict[str, float], iteration: int) \
    -> Tuple[float, float, float]:
    """å„ç¨®æå¤±é–¢æ•°å€¤ã‚’ç®—å‡ºã™ã‚‹ã€‚

    Args:
        loss (Dict[str, float]): æå¤±é–¢æ•°å€¤ã®æƒ…å ±ã€‚
        iteration (int): ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°ã€‚

    Returns:
        Tuple[float, float, float]: Total loss, Policy loss, Value lossã€‚
    """
    return loss["loss"] / iteration, loss["policy"] / iteration, \
        loss["value"] / iteration



def print_learning_process(loss_data: Dict[str, float], epoch: int, index: int, \
    iteration: int, start_time: float) -> NoReturn:
    """å­¦ç¿’çµŒéæƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹ã€‚

    Args:
        loss_data (Dict[str]): æå¤±é–¢æ•°å€¤ã®æƒ…å ±ã€‚
        epoch (int): å­¦ç¿’ã‚¨ãƒãƒƒã‚¯æ•°ã€‚
        index (int): ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã€‚
        iteration (int): ãƒãƒƒãƒã‚µã‚¤ã‚ºã®å­¦ç¿’ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°ã€‚
        start_time (float): å­¦ç¿’é–‹å§‹æ™‚é–“ã€‚
    """
    loss, policy_loss, value_loss = _calculate_losses(loss_data, iteration)
    training_time = time.time() - start_time

    print_err(f"[{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}] learn")################
    print_err(f"epoch {epoch}, data-{index} : loss = {loss:6f}, time = {training_time:.1f} [s].")
    print_err(f"\tpolicy loss : {policy_loss:6f}")
    print_err(f"\tvalue loss  : {value_loss:6f}")


def print_evaluation_information(loss_data: Dict[str, float], epoch: int, \
    iteration: int, start_time: float) -> NoReturn:
    """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®è©•ä¾¡æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹ã€‚

    Args:
        loss_data (Dict[str, float]): æå¤±é–¢æ•°å€¤ã®æƒ…å ±ã€‚
        epoch (int): å­¦ç¿’ã‚¨ãƒãƒƒã‚¯æ•°ã€‚
        iteration (int): ãƒ†ã‚¹ãƒˆã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°ã€‚
        start_time (float): è©•ä¾¡é–‹å§‹æ™‚é–“ã€‚
    """
    loss, policy_loss, value_loss = _calculate_losses(loss_data, iteration)
    testing_time = time.time() - start_time

    print_err(f"[{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}] test")################
    print_err(f"Test {epoch} : loss = {loss:6f}, time = {testing_time:3f} [s].")
    print_err(f"\tpolicy loss : {policy_loss:6f}")
    print_err(f"\tvalue loss  : {value_loss:6f}")


def save_model(network: torch.nn.Module, path: str) -> NoReturn:
    """ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹ã€‚

    Args:
        network (torch.nnModel): ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒ¢ãƒ‡ãƒ«ã€‚
        path (str): ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€‚
    """
    torch.save(network.to("cpu").state_dict(), path)


def load_data_set(path: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã‚€ã€‚ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã‚‚ã™ã‚‹ã€‚

    Args:
        path (str): ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€‚

    Returns:
        Tuple[np.ndarray, np.ndarray, np.ndarray]: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã€Policyã€Valueã€‚
    """
    data = np.load(path)

    # ãã‚Œãã‚Œã®é–¢ä¿‚ã‚’ä¿ã£ãŸã¾ã¾ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ã¦è¿”ã™
    perm = np.random.permutation(len(data["value"]))
    return data["input"][perm], \
        data["policy"][perm].astype(np.float32), \
        data["value"][perm].astype(np.int64)


def split_train_test_set(file_list: List[str], train_data_ratio: float) \
    -> Tuple[List[str], List[str]]:
    """å­¦ç¿’ã«ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ã«ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²ã™ã‚‹ã€‚

    Args:
        file_list (List[str]): å­¦ç¿’ã«ä½¿ç”¨ã™ã‚‹npzãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã€‚
        train_data_ratio (float): å­¦ç¿’ã«ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆã€‚

    Returns:
        Tuple[List[str], List[str]]: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚
    """
    train_data_set = file_list[:int(len(file_list) * train_data_ratio)]
    test_data_set = file_list[int(len(file_list) * train_data_ratio):]

    print(f"Training data set : {train_data_set}")
    print(f"Testing data set  : {test_data_set}")

    return train_data_set, test_data_set


def apply_softmax(logits: np.array) -> np.array:
    """Softmaxé–¢æ•°ã‚’é©ç”¨ã™ã‚‹ã€‚

    Args:
        logits (np.array): Softmaxé–¢æ•°ã®å…¥åŠ›å€¤ã€‚

    Returns:
        np.array: Softmaxé–¢æ•°é©ç”¨å¾Œã®å€¤ã€‚
    """
    shift_exp = np.exp(logits - np.max(logits))

    return shift_exp / np.sum(shift_exp)


def load_network(model_file_path: str, use_gpu: bool) -> DualNet:
    """ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦å–å¾—ã™ã‚‹ã€‚

    Args:
        model_file_path (str): ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€‚
        use_gpu (bool): GPUä½¿ç”¨ãƒ•ãƒ©ã‚°ã€‚

    Returns:
        DualNet: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€‚
    """
    device = get_torch_device(use_gpu=use_gpu)
    network = DualNet(device)
    network.to(device)
    try:
        network.load_state_dict(torch.load(model_file_path))
    except Exception as e: # pylint: disable=W0702
        print(f"Failed to load_network {model_file_path}.")
        raise("Failed to load_network.")
    network.eval()
    torch.set_grad_enabled(False)

    return network


from nn.network.dual_net_128_12 import DualNet_128_12

def load_DualNet_128_12(model_file_path: str, use_gpu: bool) -> DualNet_128_12:
    """ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦å–å¾—ã™ã‚‹ã€‚DualNet_128_12 ç‰ˆã€‚

    Args:
        model_file_path (str): ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€‚
        use_gpu (bool): GPUä½¿ç”¨ãƒ•ãƒ©ã‚°ã€‚

    Returns:
        DualNet: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€‚
    """
    device = get_torch_device(use_gpu=use_gpu)
    network = DualNet_128_12(device)
    network.to(device)
    try:
        network.load_state_dict(torch.load(model_file_path))
    except Exception as e: # pylint: disable=W0702
        print(f"Failed to load_DualNet_128_12 {model_file_path}.")
        raise("Failed to load_DualNet_128_12.")
    network.eval()
    torch.set_grad_enabled(False)

    return network


from nn.network.dual_net_256_24 import DualNet_256_24

def load_DualNet_256_24(model_file_path: str, use_gpu: bool) -> DualNet_128_12:
    """ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦å–å¾—ã™ã‚‹ã€‚DualNet_128_12 ç‰ˆã€‚

    Args:
        model_file_path (str): ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€‚
        use_gpu (bool): GPUä½¿ç”¨ãƒ•ãƒ©ã‚°ã€‚

    Returns:
        DualNet: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€‚
    """
    device = get_torch_device(use_gpu=use_gpu)
    network = DualNet_256_24(device)
    network.to(device)
    try:
        network.load_state_dict(torch.load(model_file_path))
    except Exception as e: # pylint: disable=W0702
        print(f"Failed to load_DualNet_256_24 {model_file_path}.")
        raise("Failed to load_DualNet_256_24.")
    network.eval()
    torch.set_grad_enabled(False)

    return network


def choose_network(network_name: str, model_file_path: str, use_gpu: bool):
    if network_name == "DualNet":
        network = load_network(model_file_path=model_file_path, use_gpu=use_gpu)
    elif network_name == "DualNet_128_12":
        network = load_DualNet_128_12(model_file_path=model_file_path, use_gpu=use_gpu)
    elif network_name == "DualNet_256_24":
        network = load_DualNet_256_24(model_file_path=model_file_path, use_gpu=use_gpu)
    else:
        print(f"ğŸ‘ºnetwork_name: {network_name} is not defined.")
        raise(f"network_name is not defined.")
    return network

TEST = "test"
"""æ·±å±¤å­¦ç¿’ã®å®Ÿè£…ã€‚
"""
import glob
import os
import time
import torch
from nn.network import DualNet, DualNet_128_12, DualNet_256_24, DualNet_semeai, DualNet_256_24_semeai
from nn.loss import calculate_policy_loss, calculate_value_loss, \
    calculate_policy_kld_loss
from nn.utility import get_torch_device, print_learning_process, \
    print_evaluation_information, save_model, load_data_set, \
    split_train_test_set, choose_network

from learning_param import SL_LEARNING_RATE, RL_LEARNING_RATE, \
    MOMENTUM, WEIGHT_DECAY, SL_VALUE_WEIGHT, RL_VALUE_WEIGHT, \
    LEARNING_SCHEDULE, BATCH_SIZE, EPOCHS

import datetime###########
dt_now = datetime.datetime.now()############

import copy##########

import numpy as np

import psutil, sys


def train_on_cpu(program_dir: str, board_size: int, batch_size: \
    int, epochs: int) -> None: # pylint: disable=R0914,R0915
    """æ•™å¸«ã‚ã‚Šå­¦ç¿’ã‚’å®Ÿè¡Œã—ã€å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹ã€‚

    Args:
        program_dir (str): ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€‚
        board_size (int): ç¢ç›¤ã®å¤§ãã•ã€‚
        batch_size (int): ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚ºã€‚
        epochs (int): å®Ÿè¡Œã™ã‚‹æœ€å¤§ã‚¨ãƒãƒƒã‚¯æ•°ã€‚
    """
    print(f"ğŸ¾train_on_cpu {dt_now}")###########

    batch_size = 1#######################


    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²
    data_set = sorted(glob.glob(os.path.join(program_dir, "data", "sl_data_*.npz")))

    train_data_set, test_data_set = split_train_test_set(data_set, 1)#################
    # train_data_set, test_data_set = split_train_test_set(data_set, 0.8)

    # å­¦ç¿’å‡¦ç†ã‚’è¡Œã†ãƒ‡ãƒã‚¤ã‚¹ã®è¨­å®š
    device = get_torch_device(use_gpu=False)
    
    dual_net = DualNet(device=device, board_size=board_size)

    dual_net.to(device)
    optimizer = torch.optim.SGD(dual_net.parameters(),
                                lr=SL_LEARNING_RATE,
                                momentum=MOMENTUM,
                                weight_decay=WEIGHT_DECAY,
                                nesterov=True)

    current_lr = SL_LEARNING_RATE

    for epoch in range(epochs):
        print(f"ğŸ¾epoch: {epoch}")############
        for data_index, train_data_path in enumerate(train_data_set):
            plane_data, policy_data, value_data = load_data_set(train_data_path)
            train_loss = {
                "loss": 0.0,
                "policy": 0.0,
                "value": 0.0,
            }
            iteration = 0
            dual_net.train()
            epoch_time = time.time()
            for i in range(0, len(value_data) - batch_size + 1, batch_size):
                print(f"ğŸ¾ãƒãƒƒãƒ: {i}")############
                plane = torch.tensor(plane_data[i:i+batch_size])
                policy = torch.tensor(policy_data[i:i+batch_size])
                value = torch.tensor(value_data[i:i+batch_size])

                print(plane)
                print(policy)
                print(value)

                policy_predict, value_predict = dual_net.forward_for_sl(plane)

                policy_loss = calculate_policy_loss(policy_predict, policy)
                value_loss = calculate_value_loss(value_predict, value)

                dual_net.zero_grad()

                loss = (policy_loss + SL_VALUE_WEIGHT * value_loss).mean()

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                train_loss["loss"] += loss.item()
                train_loss["policy"] += policy_loss.mean().item()
                train_loss["value"] += value_loss.mean().item()
                iteration += 1
                
                print("!!!dual_net\n", dual_net)
                print("!!!dual_net.state_dict().keys()\n", dual_net.state_dict().keys())############
                print("!!!dual_net.state_dict()\n", dual_net.state_dict())
                print("!!!list(dual_net.parameters()\n", list(dual_net.parameters()))
                return
            
            print_learning_process(train_loss, epoch, data_index, iteration, epoch_time)

        test_loss = {
            "loss": 0.0,
            "policy": 0.0,
            "value": 0.0,
        }
        test_iteration = 0
        testing_time = time.time()
        for data_index, test_data_path in enumerate(test_data_set):
            dual_net.eval()
            plane_data, policy_data, value_data = load_data_set(test_data_path)
            with torch.no_grad():
                for i in range(0, len(value_data) - batch_size + 1, batch_size):
                    plane = torch.tensor(plane_data[i:i+batch_size]).to(device)
                    policy = torch.tensor(policy_data[i:i+batch_size]).to(device)
                    value = torch.tensor(value_data[i:i+batch_size]).to(device)

                    policy_predict, value_predict = dual_net.forward_for_sl(plane)

                    policy_loss = calculate_policy_loss(policy_predict, policy)
                    value_loss = calculate_value_loss(value_predict, value)

                    loss = (policy_loss + SL_VALUE_WEIGHT * value_loss).mean()

                    test_loss["loss"] += loss.item()
                    test_loss["policy"] += policy_loss.mean().item()
                    test_loss["value"] += value_loss.mean().item()
                    test_iteration += 1


        print_evaluation_information(test_loss, epoch, test_iteration, testing_time)

        if epoch in LEARNING_SCHEDULE["learning_rate"]:
            previous_lr = current_lr
            for group in optimizer.param_groups:
                group["lr"] = LEARNING_SCHEDULE["learning_rate"][epoch]
            current_lr = LEARNING_SCHEDULE["learning_rate"][epoch]
            print(f"Epoch {epoch}, learning rate has changed {previous_lr} -> {current_lr}")

    save_model(dual_net, os.path.join("model", "sl-model.bin"))























def train_on_gpu(program_dir: str, board_size: int, batch_size: int, \
    epochs: int, network_name: str, npz_dir: str = "data") -> None: # pylint: disable=R0914,R0915
    """æ•™å¸«ã‚ã‚Šå­¦ç¿’ã‚’å®Ÿè¡Œã—ã€å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹ã€‚

    Args:
        program_dir (str): ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€‚
        board_size (int): ç¢ç›¤ã®å¤§ãã•ã€‚
        batch_size (int): ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚ºã€‚
        epochs (int): å®Ÿè¡Œã™ã‚‹æœ€å¤§ã‚¨ãƒãƒƒã‚¯æ•°ã€‚
    """

    print(f"ğŸ¾train_on_gpu {dt_now}")###########
    print(f"[{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}] device")#############
    print("torch.cuda.current_device: ", torch.cuda.current_device())
    print("torch.cuda.device_count: ", torch.cuda.device_count())
    print("torch.cuda.get_device_name(0): ", torch.cuda.get_device_name(0))
    if torch.cuda.device_count() > 1:##########
        print("torch.cuda.get_device_name(1): ", torch.cuda.get_device_name(1))
    print("torch.cuda.get_device_capability(0): ", torch.cuda.get_device_capability(0))
    if torch.cuda.device_count() > 1:##########
        print("torch.cuda.get_device_capability(1): ", torch.cuda.get_device_capability(1))
    print("torch.cuda.get_arch_list(): ", torch.cuda.get_arch_list())



    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²
    data_set = sorted(glob.glob(os.path.join(program_dir, npz_dir, "sl_data_*.npz")))
    """sl_data_*.npz ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆã€‚"""
    train_data_set, test_data_set = split_train_test_set(data_set, 0.8)
    """sl_data_*.npz ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²ã—ãŸã‚‚ã®ã€‚"""

    # å­¦ç¿’å‡¦ç†ã‚’è¡Œã†ãƒ‡ãƒã‚¤ã‚¹ã®è¨­å®š
    device = torch.device("cuda")
    # device = get_torch_device(use_gpu=True)######################

    if network_name == "DualNet":
        dual_net = DualNet(device=device, board_size=board_size)
        """DualNetã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã€‚å¤šåˆ†ã€ã“ã“ã«ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒ‘ãƒ©ãƒ¡ã‚¿ã¨ã‹å…¥ã£ã¦ã‚‹ã€‚"""
    elif network_name == "DualNet_128_12":
        dual_net = DualNet_128_12(device=device, board_size=board_size)
    elif network_name == "DualNet_256_24":
        dual_net = DualNet_256_24(device=device, board_size=board_size)
    elif network_name == "DualNet_semeai":
        dual_net = DualNet_semeai(device=device, board_size=board_size)
    elif network_name == "DualNet_256_24_semeai":
        dual_net = DualNet_256_24_semeai(device=device, board_size=board_size)
    else:
        print(f"ğŸ‘ºnetwork_name: {network_name} is not defined.")
        raise(f"network_name is not defined.")

    if torch.cuda.device_count() > 1:##########ã“ã“Trueã§ä½œã£ãŸã®ã§å¯¾å±€ã—ã‚ˆã†ã¨ã™ã‚‹ã¨Failed to load model/sl-model_2024ã®ã‚¨ãƒ©ãƒ¼å‡ºã‚‹
        dual_net = torch.nn.DataParallel(dual_net)

    dual_net.to(device)
    print(f"ğŸ¾device: ", device)

    optimizer = torch.optim.SGD(dual_net.parameters(),
                                lr=SL_LEARNING_RATE,
                                momentum=MOMENTUM,
                                weight_decay=WEIGHT_DECAY,
                                nesterov=True)

    scaler = torch.cuda.amp.GradScaler()
    """å‹¾é…æ¶ˆå¤±ã¨ã‹ã„ã†ã®ã‚’é˜²ãã‚„ã¤ã‚‰ã—ã„"""

    current_lr = SL_LEARNING_RATE
    """å­¦ç¿’ç‡"""

    # if device == 'cuda':###########
    #     dual_net = torch.nn.DataParallel(dual_net) # make parallel
    #     torch.backends.cuda.nn.benchmark = True

    for epoch in range(epochs):

        # npz ãƒ«ãƒ¼ãƒ—
        for data_index, train_data_path in enumerate(train_data_set):
            plane_data, policy_data, value_data = load_data_set(train_data_path)

            train_loss = {
                "loss": 0.0,
                "policy": 0.0,
                "value": 0.0,
            }

            iteration = 0

            # ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ãƒ¢ãƒ¼ãƒ‰ã«ã™ã‚‹ã€‚ãƒãƒƒãƒæ­£è¦åŒ–ã¨ã‹ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã¨ã‹è¨“ç·´æ™‚ã¨æ¨è«–æ™‚ã§æŒ™å‹•ãŒé•ã†ã‚‚ã®ãŒè¨“ç·´ãƒ¢ãƒ¼ãƒ‰ã«ãªã‚‹ã€‚ã€‚
            dual_net.train()

            # ãƒãƒƒãƒãƒ«ãƒ¼ãƒ—ã€‚epoch_time ã£ã¦ã‚ã‚‹ã‘ã©å¤šåˆ†ãƒãƒƒãƒã®æ™‚é–“ã‚’è¨ˆæ¸¬ã—ã¦ã‚‹ã€‚
            epoch_time = time.time()
            for i in range(0, len(value_data) - batch_size + 1, batch_size):
                with torch.cuda.amp.autocast(enabled=True):
                    plane = torch.tensor(plane_data[i:i+batch_size]).to(device)
                    """ç›¤é¢ãƒ‡ãƒ¼ã‚¿ã®ãƒŸãƒ‹ãƒãƒƒãƒã®ãƒªã‚¹ãƒˆã€‚81*6*batch_size ã®ãƒ†ãƒ³ã‚½ãƒ«ã€‚"""
                    policy = torch.tensor(policy_data[i:i+batch_size]).to(device)
                    value = torch.tensor(value_data[i:i+batch_size]).to(device)

                    policy_predict, value_predict = dual_net(plane, pram="sl")
                    # if torch.cuda.device_count() > 1:
                    #     policy_predict, value_predict = dual_net(plane)##################
                    #     # policy_predict, value_predict = dual_net.module.forward_for_sl(plane)
                    # else:
                    #     policy_predict, value_predict = dual_net.forward_for_sl(plane)
                    # # policy_predict, value_predict = dual_net.forward_for_sl(plane)###################def

                    # ãƒ¢ãƒ‡ãƒ«ã®å‹¾é…ã‚’åˆæœŸåŒ–
                    # ãŸã¶ã‚“ã€ãƒŸãƒ‹ãƒãƒƒãƒå­¦ç¿’ã§ä½¿ã†ãŸã‚ã«ãƒŸãƒ‹ãƒãƒƒãƒå†…ã®å‹¾é…ã‚’è¨˜éŒ²ã—ã¦ã„ã¦ã€å‰ã®ãƒŸãƒ‹ãƒãƒƒãƒã®å‹¾é…ãŒæ®‹ã£ã¦ã„ã‚‹ã®ã§ã€ãã‚Œã‚’åˆæœŸåŒ–ã—ã¦ã„ã‚‹ã€‚
                    # ï¼Ÿwith ã®ä¸Šã«ç§»å‹•ã™ã‚‹ï¼Ÿ
                    dual_net.zero_grad()

                    # ãƒ­ã‚¹ã®è¨ˆç®—
                    policy_loss = calculate_policy_loss(policy_predict, policy)
                    value_loss = calculate_value_loss(value_predict, value)

                    # å¤šåˆ†ã€policy_loss ã®ãŒé‡è¦ã ã‹ã‚‰ã€value_loss ã«å¾®å°é‡ã®é‡ã¿ã‚’ã‹ã‘ã¦ã‚‹ 
                    loss = (policy_loss + SL_VALUE_WEIGHT * value_loss).mean()

                scaler.scale(loss).backward()
                # é‡ã¿ã®æ›´æ–°ã‚’ã—ã¦ã‚‹ï¼Ÿ
                scaler.step(optimizer)
                scaler.update()

                train_loss["loss"] += loss.item()
                train_loss["policy"] += policy_loss.mean().item()
                train_loss["value"] += value_loss.mean().item()
                iteration += 1

            print_learning_process(train_loss, epoch, data_index, iteration, epoch_time)

        test_loss = {
            "loss": 0.0,
            "policy": 0.0,
            "value": 0.0,
        }
        test_iteration = 0
        testing_time = time.time()
        for data_index, test_data_path in enumerate(test_data_set):
            dual_net.eval()
            plane_data, policy_data, value_data = load_data_set(test_data_path)
            with torch.no_grad():
                for i in range(0, len(value_data) - batch_size + 1, batch_size):
                    plane = torch.tensor(plane_data[i:i+batch_size]).to(device)
                    policy = torch.tensor(policy_data[i:i+batch_size]).to(device)
                    value = torch.tensor(value_data[i:i+batch_size]).to(device)

                    policy_predict, value_predict = dual_net(plane, pram="sl")
                    # if torch.cuda.device_count() > 1:
                    #     policy_predict, value_predict = dual_net(plane)##################
                    #     # policy_predict, value_predict = dual_net.module.forward_for_sl(plane)
                    # else:
                    #     policy_predict, value_predict = dual_net.forward_for_sl(plane)
                    # # policy_predict, value_predict = dual_net.forward_for_sl(plane)############def

                    policy_loss = calculate_policy_loss(policy_predict, policy)
                    value_loss = calculate_value_loss(value_predict, value)

                    loss = (policy_loss + SL_VALUE_WEIGHT * value_loss).mean()

                    test_loss["loss"] += loss.item()
                    test_loss["policy"] += policy_loss.mean().item()
                    test_loss["value"] += value_loss.mean().item()
                    test_iteration += 1


        print_evaluation_information(test_loss, epoch, test_iteration, testing_time)

        # å­¦ç¿’ç‡ã‚’å¤‰æ›´ã™ã‚‹
        if epoch in LEARNING_SCHEDULE["learning_rate"]:
            previous_lr = current_lr
            for group in optimizer.param_groups:
                group["lr"] = LEARNING_SCHEDULE["learning_rate"][epoch]
            current_lr = LEARNING_SCHEDULE["learning_rate"][epoch]
            print(f"Epoch {epoch}, learning rate has changed {previous_lr} -> {current_lr}")

        # ãŸã¶ã‚“ã€save_model ã™ã‚‹ã¨å¤‰æ›´ãŒå…¥ã‚‹ã®ã§ã€ãƒ‡ã‚£ãƒ¼ãƒ—ã‚³ãƒ”ãƒ¼ã‚’ä½œã£ã¦ãã‚Œã‚’ä¿å­˜ã™ã‚‹ã€‚
        dual_net_copy = copy.deepcopy(dual_net)######
        # ãƒ¢ãƒ‡ãƒ«ãŒDataParallelã§ãƒ©ãƒƒãƒ—ã•ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’ç¢ºèª
        if isinstance(dual_net_copy, torch.nn.DataParallel):
            state_dict = dual_net_copy.module.state_dict()
        else:
            state_dict = dual_net_copy.state_dict()

        # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
        torch.save(state_dict, os.path.join("model", f"sl-model_{dt_now.strftime('%Y%m%d_%H%M%S')}_Ep{epoch:0>2}.bin"))
        # torch.save(dual_net_copy.to("cpu").module.state_dict(), os.path.join("model", f"sl-model_{dt_now.strftime('%Y%m%d_%H%M%S')}_Ep:{epoch:0>2}.bin"))
        # save_model(dual_net_copy, os.path.join("model", f"sl-model_{dt_now.strftime('%Y%m%d_%H%M%S')}_Ep:{epoch:0>2}.bin"))######epochæ¯ã«ä¿å­˜

    # save_model(dual_net, os.path.join("model", "sl-model.bin"))






def train_on_gpu_ddp_worker(rank, world, train_npz_paths, test_npz_paths, program_dir: str, board_size: int, batch_size: int, epochs: int, network_name: str, npz_dir: str = "data", checkpoint_dir: str = None) -> None: # pylint: disable=R0914,R0915
    """æ•™å¸«ã‚ã‚Šå­¦ç¿’ã‚’å®Ÿè¡Œã—ã€å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹ã€‚

    Args:
        program_dir (str): ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€‚
        board_size (int): ç¢ç›¤ã®å¤§ãã•ã€‚
        batch_size (int): ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚ºã€‚
        epochs (int): å®Ÿè¡Œã™ã‚‹æœ€å¤§ã‚¨ãƒãƒƒã‚¯æ•°ã€‚
    """

    assert batch_size % world == 0
    batch_size = batch_size // world

    torch.distributed.init_process_group("nccl", rank = rank, world_size = world)


    if network_name == "DualNet":
        dual_net = DualNet(device=rank, board_size=board_size)
        """DualNetã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã€‚å¤šåˆ†ã€ã“ã“ã«ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒ‘ãƒ©ãƒ¡ã‚¿ã¨ã‹å…¥ã£ã¦ã‚‹ã€‚"""
    elif network_name == "DualNet_128_12":
        dual_net = DualNet_128_12(device=rank, board_size=board_size)
    elif network_name == "DualNet_256_24":
        dual_net = DualNet_256_24(device=rank, board_size=board_size)
    elif network_name == "DualNet_semeai":
        dual_net = DualNet_semeai(device=rank, board_size=board_size)
    elif network_name == "DualNet_256_24_semeai":
        dual_net = DualNet_256_24_semeai(device=rank, board_size=board_size)
    else:
        print(f"ğŸ‘ºnetwork_name: {network_name} is not defined.")
        raise(f"network_name is not defined.")
    
    if checkpoint_dir is not None:
        checkpoint = torch.load(checkpoint_dir)
        state_dict = checkpoint['model_state_dict']
        
        # DataParallelã§ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®state_dictã‚’ä¿®æ­£
        from collections import OrderedDict
        new_state_dict = OrderedDict()
        for k, v in state_dict.items():
            if k.startswith('module.'):
                name = k[7:] # module.ã‚’å–ã‚Šé™¤ã
                new_state_dict[name] = v
            else:
                new_state_dict[k] = v
        
        dual_net.load_state_dict(new_state_dict)
        policy_loss = checkpoint['policy_loss']
        value_loss = checkpoint['value_loss']

    print(f"ğŸ¾device: ", rank)#############
    dual_net = dual_net.to(rank)
    dual_net = torch.nn.parallel.DistributedDataParallel(dual_net, device_ids = [rank], output_device = rank, find_unused_parameters=False)

    optimizer = torch.optim.SGD(dual_net.parameters(),
                                lr=SL_LEARNING_RATE,
                                momentum=MOMENTUM,
                                weight_decay=WEIGHT_DECAY,
                                nesterov=True)

    if checkpoint_dir is not None:
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

    scaler = torch.cuda.amp.GradScaler()
    """å‹¾é…æ¶ˆå¤±ã¨ã‹ã„ã†ã®ã‚’é˜²ãã‚„ã¤ã‚‰ã—ã„"""

    current_lr = SL_LEARNING_RATE
    """å­¦ç¿’ç‡"""


    def tmp_load_data_set(npz_path, rank):
        def check_memory_usage():
            if not psutil.virtual_memory().percent < 90:
                print(f"memory usage is too high. mem_use: {psutil.virtual_memory().percent}% [{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}]")
                assert True

        check_memory_usage()

        data = np.load(npz_path)

        check_memory_usage()

        plane_data = data["input"]
        policy_data = data["policy"].astype(np.float32)
        value_data = data["value"].astype(np.int64)

        check_memory_usage()

        plane_data = torch.tensor(plane_data)
        policy_data = torch.tensor(policy_data)
        value_data = torch.tensor(value_data)

        return plane_data, policy_data, value_data


    for epoch in range(epochs):

        npz_cnt = 0

        # npz ãƒ«ãƒ¼ãƒ—
        for data_index, train_npz_path in enumerate(train_npz_paths):

            plane_data, policy_data, value_data = tmp_load_data_set(train_npz_path, rank)

            train_dataset = torch.utils.data.TensorDataset(plane_data, policy_data, value_data)

            train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset, num_replicas = world, rank = rank, shuffle = True)

            # samplerã®è¨­å®šã¨shuffleã‚’Falseã«ã™ã‚‹ã“ã¨ã‚’å¿˜ã‚Œãªã„
            train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = False, pin_memory=True, num_workers = 2, sampler = train_sampler)


            train_sampler.set_epoch(epoch)


            train_loss = {
                "loss": 0.0,
                "policy": 0.0,
                "value": 0.0,
            }

            iteration = 0

            dual_net.train()

            epoch_time = time.time()
            for train_batch in train_loader:
                # if iteration % 1000 == 0:##############
                #         print(f"\r{train_npz_path}, iteration: {iteration}/{len(train_loader)}, rank: {rank}", end="")##########
                #         sys.stdout.flush()
                with torch.cuda.amp.autocast(enabled=True):

                    plane, policy, value = train_batch
                    plane = plane.to(rank, non_blocking=True)
                    policy = policy.to(rank, non_blocking=True)
                    value = value.to(rank, non_blocking=True)

                    policy_predict, value_predict = dual_net(plane, pram="sl")

                    dual_net.zero_grad()

                    # ãƒ­ã‚¹ã®è¨ˆç®—
                    policy_loss = calculate_policy_loss(policy_predict, policy)
                    value_loss = calculate_value_loss(value_predict, value)

                    # å¤šåˆ†ã€policy_loss ã®ãŒé‡è¦ã ã‹ã‚‰ã€value_loss ã«å¾®å°é‡ã®é‡ã¿ã‚’ã‹ã‘ã¦ã‚‹ 
                    loss = (policy_loss + SL_VALUE_WEIGHT * value_loss).mean()

                scaler.scale(loss).backward()
                # é‡ã¿ã®æ›´æ–°ã‚’ã—ã¦ã‚‹ï¼Ÿ
                scaler.step(optimizer)
                scaler.update()

                torch.distributed.all_reduce(loss, op=torch.distributed.ReduceOp.AVG)
                torch.distributed.all_reduce(policy_loss, op=torch.distributed.ReduceOp.AVG)
                torch.distributed.all_reduce(value_loss, op=torch.distributed.ReduceOp.AVG)

                train_loss["loss"] += loss.item()
                train_loss["policy"] += policy_loss.mean().item()
                train_loss["value"] += value_loss.mean().item()
                iteration += 1


            if int(rank) == 0:
                print_learning_process(train_loss, epoch, data_index, iteration, epoch_time)
                npz_cnt += 1
                if npz_cnt % 10 == 0:
                    dual_net_copy = copy.deepcopy(dual_net)######
                    torch.save(dual_net_copy.to("cpu").module.state_dict(), os.path.join("model", f"sl-model_{dt_now.strftime('%Y%m%d_%H%M%S')}_{npz_cnt:0>3}.bin"))
                    # save_model(dual_net_copy, os.path.join("model", f"sl-model_{dt_now.strftime('%Y%m%d_%H%M%S')}_Ep:{epoch:0>2}.bin"))######epochæ¯ã«ä¿å­˜

                    torch.save({
                        'epoch': epoch,
                        'model_state_dict': dual_net.state_dict(),
                        'optimizer_state_dict': optimizer.state_dict(),
                        'policy_loss': policy_loss,
                        'value_loss': value_loss,
                        }, os.path.join("model", f"checkpoint_{dt_now.strftime('%Y%m%d_%H%M%S')}_{npz_cnt:0>3}.bin"))


        test_loss = {
            "loss": 0.0,
            "policy": 0.0,
            "value": 0.0,
        }
        test_iteration = 0
        testing_time = time.time()
        for data_index, test_npz_path in enumerate(test_npz_paths):

            plane_data, policy_data, value_data = tmp_load_data_set(test_npz_path, rank)

            test_dataset = torch.utils.data.TensorDataset(plane_data, policy_data, value_data)

            test_sampler = torch.utils.data.distributed.DistributedSampler(test_dataset, num_replicas = world, rank = rank, shuffle = False)

            test_sampler.set_epoch(epoch)

            test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle = False, pin_memory=True, num_workers = 2, sampler = test_sampler)

            torch.distributed.barrier()

            dual_net.eval()
            with torch.no_grad():
                for test_batch in test_loader:
                    # if test_iteration % 1000 == 0:##############
                    #     print(f"\r{test_npz_path}, test_iteration: {test_iteration}/{len(test_loader)}, rank: {rank}", end="")##########
                    #     sys.stdout.flush()
                    with torch.cuda.amp.autocast(enabled=True):
                        plane, policy, value = test_batch
                        plane = plane.to(rank, non_blocking=True)
                        policy = policy.to(rank, non_blocking=True)
                        value = value.to(rank, non_blocking=True)

                        policy_predict, value_predict = dual_net(plane, pram="sl")

                        policy_loss = calculate_policy_loss(policy_predict, policy)
                        value_loss = calculate_value_loss(value_predict, value)

                        loss = (policy_loss + SL_VALUE_WEIGHT * value_loss).mean()

                    torch.distributed.all_reduce(loss, op=torch.distributed.ReduceOp.AVG)
                    torch.distributed.all_reduce(policy_loss, op=torch.distributed.ReduceOp.AVG)
                    torch.distributed.all_reduce(value_loss, op=torch.distributed.ReduceOp.AVG)

                    test_loss["loss"] += loss.item()
                    test_loss["policy"] += policy_loss.mean().item()
                    test_loss["value"] += value_loss.mean().item()
                    test_iteration += 1

        if int(rank) == 0:
            print_evaluation_information(test_loss, epoch, test_iteration, testing_time)

        torch.distributed.barrier()
        # å­¦ç¿’ç‡ã‚’å¤‰æ›´ã™ã‚‹
        if epoch in LEARNING_SCHEDULE["learning_rate"]:
            previous_lr = current_lr
            for group in optimizer.param_groups:
                group["lr"] = LEARNING_SCHEDULE["learning_rate"][epoch]
            current_lr = LEARNING_SCHEDULE["learning_rate"][epoch]
            print(f"Epoch {epoch}, learning rate has changed {previous_lr} -> {current_lr}")

        if int(rank) == 0:
            # ãŸã¶ã‚“ã€save_model ã™ã‚‹ã¨å¤‰æ›´ãŒå…¥ã‚‹ã®ã§ã€ãƒ‡ã‚£ãƒ¼ãƒ—ã‚³ãƒ”ãƒ¼ã‚’ä½œã£ã¦ãã‚Œã‚’ä¿å­˜ã™ã‚‹ã€‚
            dual_net_copy = copy.deepcopy(dual_net)######
            torch.save(dual_net_copy.to("cpu").module.state_dict(), os.path.join("model", f"sl-model_{dt_now.strftime('%Y%m%d_%H%M%S')}_Ep{epoch:0>2}.bin"))
            # save_model(dual_net_copy, os.path.join("model", f"sl-model_{dt_now.strftime('%Y%m%d_%H%M%S')}_Ep:{epoch:0>2}.bin"))######epochæ¯ã«ä¿å­˜

            torch.save({
                'epoch': epoch,
                'model_state_dict': dual_net.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'policy_loss': policy_loss,
                'value_loss': value_loss,
                }, os.path.join("model", f"checkpoint_{dt_now.strftime('%Y%m%d_%H%M%S')}_Ep{epoch:0>2}.bin"))

    # save_model(dual_net, os.path.join("model", "sl-model.bin"))

    torch.distributed.destroy_process_group()




def train_on_gpu_ddp(program_dir: str, board_size: int, batch_size: int, epochs: int, network_name: str, npz_dir: str = "data", chckpoint_dir: str = None) -> None: # pylint: disable=R0914,R0915

    print(f"ğŸ¾train_on_gpu_ddp {dt_now}")###########
    print(f"    [{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}] device")#############
    print("    torch.cuda.current_device: ", torch.cuda.current_device())
    print("    torch.cuda.device_count: ", torch.cuda.device_count())
    print("    torch.cuda.get_device_name(0): ", torch.cuda.get_device_name(0))
    for i in range(torch.cuda.device_count()):
        print(f"    torch.cuda.get_device_name({i}): ", torch.cuda.get_device_name(i))
    # if torch.cuda.device_count() > 1:##########
    #     print("    torch.cuda.get_device_name(1): ", torch.cuda.get_device_name(1))
    for i in range(torch.cuda.device_count()):
        print(f"    torch.cuda.get_device_capability({i}): ", torch.cuda.get_device_capability(i))
    # print("    torch.cuda.get_device_capability(0): ", torch.cuda.get_device_capability(0))
    # if torch.cuda.device_count() > 1:##########
        # print("    torch.cuda.get_device_capability(1): ", torch.cuda.get_device_capability(1))
    print("    torch.cuda.get_arch_list(): ", torch.cuda.get_arch_list())

    # train_dataset, val_dataset = getMyDataset()

    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²
    data_set = sorted(glob.glob(os.path.join(program_dir, npz_dir, "sl_data_*.npz")))
    """sl_data_*.npz ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆã€‚"""
    train_data_set, test_data_set = split_train_test_set(data_set, 0.8)
    """sl_data_*.npz ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²ã—ãŸã‚‚ã®ã€‚"""

    os.environ['MASTER_ADDR'] = 'localhost'
    os.environ['MASTER_PORT'] = '50000'
    os.environ['TORCH_DISTRIBUTED_DEBUG'] = 'DETAIL'
    os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'
    # os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'

    torch.multiprocessing.spawn(train_on_gpu_ddp_worker, args=(torch.cuda.device_count(), train_data_set, test_data_set, program_dir, board_size, BATCH_SIZE, EPOCHS, network_name, npz_dir, chckpoint_dir), nprocs = torch.cuda.device_count(), join = True)




def train_on_gpu_ddp_worker2(rank, world, train_npz_paths, test_npz_paths, program_dir: str, board_size: int, batch_size: int, epochs: int, network_name: str, npz_dir: str = "data", checkpoint_dir: str = None) -> None: # pylint: disable=R0914,R0915
    """æ•™å¸«ã‚ã‚Šå­¦ç¿’ã‚’å®Ÿè¡Œã—ã€å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹ã€‚

    Args:
        program_dir (str): ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€‚
        board_size (int): ç¢ç›¤ã®å¤§ãã•ã€‚
        batch_size (int): ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚ºã€‚
        epochs (int): å®Ÿè¡Œã™ã‚‹æœ€å¤§ã‚¨ãƒãƒƒã‚¯æ•°ã€‚
    """

    assert batch_size % world == 0
    batch_size = batch_size // world

    torch.distributed.init_process_group("nccl", rank = rank, world_size = world)


    if network_name == "DualNet":
        dual_net = DualNet(device=rank, board_size=board_size)
        """DualNetã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã€‚å¤šåˆ†ã€ã“ã“ã«ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒ‘ãƒ©ãƒ¡ã‚¿ã¨ã‹å…¥ã£ã¦ã‚‹ã€‚"""
    elif network_name == "DualNet_128_12":
        dual_net = DualNet_128_12(device=rank, board_size=board_size)
    elif network_name == "DualNet_256_24":
        dual_net = DualNet_256_24(device=rank, board_size=board_size)
    elif network_name == "DualNet_semeai":
        dual_net = DualNet_semeai(device=rank, board_size=board_size)
    elif network_name == "DualNet_256_24_semeai":
        dual_net = DualNet_256_24_semeai(device=rank, board_size=board_size)
    else:
        print(f"ğŸ‘ºnetwork_name: {network_name} is not defined.")
        raise(f"network_name is not defined.")
    
    if checkpoint_dir is not None:
        checkpoint = torch.load(checkpoint_dir)
        state_dict = checkpoint['model_state_dict']
        
        # DataParallelã§ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®state_dictã‚’ä¿®æ­£
        from collections import OrderedDict
        new_state_dict = OrderedDict()
        for k, v in state_dict.items():
            if k.startswith('module.'):
                name = k[7:] # module.ã‚’å–ã‚Šé™¤ã
                new_state_dict[name] = v
            else:
                new_state_dict[k] = v
        
        dual_net.load_state_dict(new_state_dict)
        policy_loss = checkpoint['policy_loss']
        value_loss = checkpoint['value_loss']

    print(f"ğŸ¾device: ", rank)#############
    dual_net = dual_net.to(rank)
    dual_net = torch.nn.parallel.DistributedDataParallel(dual_net, device_ids = [rank], output_device = rank, find_unused_parameters=False)

    optimizer = torch.optim.SGD(dual_net.parameters(),
                                lr=SL_LEARNING_RATE,
                                momentum=MOMENTUM,
                                weight_decay=WEIGHT_DECAY,
                                nesterov=True)

    if checkpoint_dir is not None:
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

    scaler = torch.cuda.amp.GradScaler()
    """å‹¾é…æ¶ˆå¤±ã¨ã‹ã„ã†ã®ã‚’é˜²ãã‚„ã¤ã‚‰ã—ã„"""

    current_lr = SL_LEARNING_RATE
    """å­¦ç¿’ç‡"""


    def tmp_load_data_set(npz_path, rank):
        def check_memory_usage():
            if not psutil.virtual_memory().percent < 90:
                print(f"memory usage is too high. mem_use: {psutil.virtual_memory().percent}% [{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}]")
                assert True

        check_memory_usage()

        data = np.load(npz_path)

        check_memory_usage()

        plane_data = data["input"]
        policy_data = data["policy"].astype(np.float32)
        value_data = data["value"].astype(np.int64)

        check_memory_usage()

        plane_data = torch.tensor(plane_data)
        policy_data = torch.tensor(policy_data)
        value_data = torch.tensor(value_data)

        return plane_data, policy_data, value_data


    for epoch in range(epochs):

        npz_cnt = 0

        # npz ãƒ«ãƒ¼ãƒ—
        while True:
        # for data_index, train_npz_path in enumerate(train_npz_paths):

            sleep_cnt = 0
            sleep_time = time.time()
            while not os.path.isfile(os.path.join(program_dir, npz_dir, f"sl_data_{npz_cnt}.npz")):
                time.sleep(1)
                sleep_cnt += 1
                if time.time() - sleep_time > 3600:
                    break

            train_npz_path = os.path.join(program_dir, npz_dir, f"sl_data_{npz_cnt}.npz")

            plane_data, policy_data, value_data = tmp_load_data_set(train_npz_path, rank)

            train_dataset = torch.utils.data.TensorDataset(plane_data, policy_data, value_data)

            train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset, num_replicas = world, rank = rank, shuffle = True)

            # samplerã®è¨­å®šã¨shuffleã‚’Falseã«ã™ã‚‹ã“ã¨ã‚’å¿˜ã‚Œãªã„
            train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = False, pin_memory=True, num_workers = 2, sampler = train_sampler)


            train_sampler.set_epoch(epoch)


            train_loss = {
                "loss": 0.0,
                "policy": 0.0,
                "value": 0.0,
            }

            iteration = 0

            dual_net.train()

            epoch_time = time.time()
            for train_batch in train_loader:
                # if iteration % 1000 == 0:##############
                #         print(f"\r{train_npz_path}, iteration: {iteration}/{len(train_loader)}, rank: {rank}", end="")##########
                #         sys.stdout.flush()
                with torch.cuda.amp.autocast(enabled=True):

                    plane, policy, value = train_batch
                    plane = plane.to(rank, non_blocking=True)
                    policy = policy.to(rank, non_blocking=True)
                    value = value.to(rank, non_blocking=True)

                    policy_predict, value_predict = dual_net(plane, pram="sl")

                    dual_net.zero_grad()

                    # ãƒ­ã‚¹ã®è¨ˆç®—
                    policy_loss = calculate_policy_loss(policy_predict, policy)
                    value_loss = calculate_value_loss(value_predict, value)

                    # å¤šåˆ†ã€policy_loss ã®ãŒé‡è¦ã ã‹ã‚‰ã€value_loss ã«å¾®å°é‡ã®é‡ã¿ã‚’ã‹ã‘ã¦ã‚‹ 
                    loss = (policy_loss + SL_VALUE_WEIGHT * value_loss).mean()

                scaler.scale(loss).backward()
                # é‡ã¿ã®æ›´æ–°ã‚’ã—ã¦ã‚‹ï¼Ÿ
                scaler.step(optimizer)
                scaler.update()

                torch.distributed.all_reduce(loss, op=torch.distributed.ReduceOp.AVG)
                torch.distributed.all_reduce(policy_loss, op=torch.distributed.ReduceOp.AVG)
                torch.distributed.all_reduce(value_loss, op=torch.distributed.ReduceOp.AVG)

                train_loss["loss"] += loss.item()
                train_loss["policy"] += policy_loss.mean().item()
                train_loss["value"] += value_loss.mean().item()
                iteration += 1


            if int(rank) == 0:
                print_learning_process(train_loss, epoch, f"sl_data_{npz_cnt}.npz", iteration, epoch_time)
                npz_cnt += 1
                if npz_cnt % 10 == 0:
                    dual_net_copy = copy.deepcopy(dual_net)######
                    torch.save(dual_net_copy.to("cpu").module.state_dict(), os.path.join("model", f"sl-model_{dt_now.strftime('%Y%m%d_%H%M%S')}_{npz_cnt:0>3}.bin"))
                    # save_model(dual_net_copy, os.path.join("model", f"sl-model_{dt_now.strftime('%Y%m%d_%H%M%S')}_Ep:{epoch:0>2}.bin"))######epochæ¯ã«ä¿å­˜

                    torch.save({
                        'epoch': epoch,
                        'model_state_dict': dual_net.state_dict(),
                        'optimizer_state_dict': optimizer.state_dict(),
                        'policy_loss': policy_loss,
                        'value_loss': value_loss,
                        }, os.path.join("model", f"checkpoint_{dt_now.strftime('%Y%m%d_%H%M%S')}_{npz_cnt:0>3}.bin"))
            
            
            npz_cnt += 1


        test_loss = {
            "loss": 0.0,
            "policy": 0.0,
            "value": 0.0,
        }
        test_iteration = 0
        testing_time = time.time()
        for data_index, test_npz_path in enumerate(test_npz_paths):

            plane_data, policy_data, value_data = tmp_load_data_set(test_npz_path, rank)

            test_dataset = torch.utils.data.TensorDataset(plane_data, policy_data, value_data)

            test_sampler = torch.utils.data.distributed.DistributedSampler(test_dataset, num_replicas = world, rank = rank, shuffle = False)

            test_sampler.set_epoch(epoch)

            test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle = False, pin_memory=True, num_workers = 2, sampler = test_sampler)

            torch.distributed.barrier()

            dual_net.eval()
            with torch.no_grad():
                for test_batch in test_loader:
                    # if test_iteration % 1000 == 0:##############
                    #     print(f"\r{test_npz_path}, test_iteration: {test_iteration}/{len(test_loader)}, rank: {rank}", end="")##########
                    #     sys.stdout.flush()
                    with torch.cuda.amp.autocast(enabled=True):
                        plane, policy, value = test_batch
                        plane = plane.to(rank, non_blocking=True)
                        policy = policy.to(rank, non_blocking=True)
                        value = value.to(rank, non_blocking=True)

                        policy_predict, value_predict = dual_net(plane, pram="sl")

                        policy_loss = calculate_policy_loss(policy_predict, policy)
                        value_loss = calculate_value_loss(value_predict, value)

                        loss = (policy_loss + SL_VALUE_WEIGHT * value_loss).mean()

                    torch.distributed.all_reduce(loss, op=torch.distributed.ReduceOp.AVG)
                    torch.distributed.all_reduce(policy_loss, op=torch.distributed.ReduceOp.AVG)
                    torch.distributed.all_reduce(value_loss, op=torch.distributed.ReduceOp.AVG)

                    test_loss["loss"] += loss.item()
                    test_loss["policy"] += policy_loss.mean().item()
                    test_loss["value"] += value_loss.mean().item()
                    test_iteration += 1

        if int(rank) == 0:
            print_evaluation_information(test_loss, epoch, test_iteration, testing_time)

        torch.distributed.barrier()
        # å­¦ç¿’ç‡ã‚’å¤‰æ›´ã™ã‚‹
        if epoch in LEARNING_SCHEDULE["learning_rate"]:
            previous_lr = current_lr
            for group in optimizer.param_groups:
                group["lr"] = LEARNING_SCHEDULE["learning_rate"][epoch]
            current_lr = LEARNING_SCHEDULE["learning_rate"][epoch]
            print(f"Epoch {epoch}, learning rate has changed {previous_lr} -> {current_lr}")

        if int(rank) == 0:
            # ãŸã¶ã‚“ã€save_model ã™ã‚‹ã¨å¤‰æ›´ãŒå…¥ã‚‹ã®ã§ã€ãƒ‡ã‚£ãƒ¼ãƒ—ã‚³ãƒ”ãƒ¼ã‚’ä½œã£ã¦ãã‚Œã‚’ä¿å­˜ã™ã‚‹ã€‚
            dual_net_copy = copy.deepcopy(dual_net)######
            torch.save(dual_net_copy.to("cpu").module.state_dict(), os.path.join("model", f"sl-model_{dt_now.strftime('%Y%m%d_%H%M%S')}_Ep{epoch:0>2}.bin"))
            # save_model(dual_net_copy, os.path.join("model", f"sl-model_{dt_now.strftime('%Y%m%d_%H%M%S')}_Ep:{epoch:0>2}.bin"))######epochæ¯ã«ä¿å­˜

            torch.save({
                'epoch': epoch,
                'model_state_dict': dual_net.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'policy_loss': policy_loss,
                'value_loss': value_loss,
                }, os.path.join("model", f"checkpoint_{dt_now.strftime('%Y%m%d_%H%M%S')}_Ep{epoch:0>2}.bin"))

    # save_model(dual_net, os.path.join("model", "sl-model.bin"))

    torch.distributed.destroy_process_group()





def train_on_gpu_ddp2(program_dir: str, board_size: int, batch_size: int, epochs: int, network_name: str, npz_dir: str = "data", chckpoint_dir: str = None) -> None: # pylint: disable=R0914,R0915

    print(f"ğŸ¾train_on_gpu_ddp {dt_now}")###########
    print(f"    [{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}] device")#############
    print("    torch.cuda.current_device: ", torch.cuda.current_device())
    print("    torch.cuda.device_count: ", torch.cuda.device_count())
    print("    torch.cuda.get_device_name(0): ", torch.cuda.get_device_name(0))
    for i in range(torch.cuda.device_count()):
        print(f"    torch.cuda.get_device_name({i}): ", torch.cuda.get_device_name(i))
    # if torch.cuda.device_count() > 1:##########
    #     print("    torch.cuda.get_device_name(1): ", torch.cuda.get_device_name(1))
    for i in range(torch.cuda.device_count()):
        print(f"    torch.cuda.get_device_capability({i}): ", torch.cuda.get_device_capability(i))
    # print("    torch.cuda.get_device_capability(0): ", torch.cuda.get_device_capability(0))
    # if torch.cuda.device_count() > 1:##########
        # print("    torch.cuda.get_device_capability(1): ", torch.cuda.get_device_capability(1))
    print("    torch.cuda.get_arch_list(): ", torch.cuda.get_arch_list())

    # train_dataset, val_dataset = getMyDataset()

    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²
    data_set = sorted(glob.glob(os.path.join(program_dir, npz_dir, "sl_data_*.npz")))
    """sl_data_*.npz ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆã€‚"""
    train_data_set, test_data_set = split_train_test_set(data_set, 0.8)
    """sl_data_*.npz ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²ã—ãŸã‚‚ã®ã€‚"""

    os.environ['MASTER_ADDR'] = 'localhost'
    os.environ['MASTER_PORT'] = '50000'
    os.environ['TORCH_DISTRIBUTED_DEBUG'] = 'DETAIL'
    os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'
    # os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'

    torch.multiprocessing.spawn(train_on_gpu_ddp_worker2, args=(torch.cuda.device_count(), train_data_set, test_data_set, program_dir, board_size, BATCH_SIZE, EPOCHS, network_name, npz_dir, chckpoint_dir), nprocs = torch.cuda.device_count(), join = True)











# def train_on_gpu(program_dir: str, board_size: int, batch_size: int, \
#     epochs: int, network_name: str, npz_dir: str = "data") -> None: # pylint: disable=R0914,R0915
#     """æ•™å¸«ã‚ã‚Šå­¦ç¿’ã‚’å®Ÿè¡Œã—ã€å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹ã€‚

#     Args:
#         program_dir (str): ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€‚
#         board_size (int): ç¢ç›¤ã®å¤§ãã•ã€‚
#         batch_size (int): ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚ºã€‚
#         epochs (int): å®Ÿè¡Œã™ã‚‹æœ€å¤§ã‚¨ãƒãƒƒã‚¯æ•°ã€‚
#     """

#     print(f"ğŸ¾train_on_gpu {dt_now}")###########
#     print(f"[{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}] device")#############
#     print("torch.cuda.current_device: ", torch.cuda.current_device())
#     print("torch.cuda.device_count: ", torch.cuda.device_count())
#     print("torch.cuda.get_device_name(0): ", torch.cuda.get_device_name(0))
#     if torch.cuda.device_count() > 1:##########
#         print("torch.cuda.get_device_name(1): ", torch.cuda.get_device_name(1))
#     print("torch.cuda.get_device_capability(0): ", torch.cuda.get_device_capability(0))
#     if torch.cuda.device_count() > 1:##########
#         print("torch.cuda.get_device_capability(1): ", torch.cuda.get_device_capability(1))
#     print("torch.cuda.get_arch_list(): ", torch.cuda.get_arch_list())

#     # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²
#     data_set = sorted(glob.glob(os.path.join(program_dir, npz_dir, "sl_data_*.npz")))
#     train_data_set, test_data_set = split_train_test_set(data_set, 0.8)

#     # å­¦ç¿’å‡¦ç†ã‚’è¡Œã†ãƒ‡ãƒã‚¤ã‚¹ã®è¨­å®š
#     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#     if network_name == "DualNet":
#         dual_net = DualNet(device=device, board_size=board_size)
#     elif network_name == "DualNet_128_12":
#         dual_net = DualNet_128_12(device=device, board_size=board_size)
#     elif network_name == "DualNet_256_24":
#         dual_net = DualNet_256_24(device=device, board_size=board_size)
#     else:
#         print(f"ğŸ‘ºnetwork_name: {network_name} is not defined.")
#         raise ValueError(f"network_name: {network_name} is not defined.")

#     if torch.cuda.device_count() > 1:
#         dual_net = torch.nn.DataParallel(dual_net)

#     dual_net.to(device)
#     print(f"ğŸ¾device: ", device)

#     optimizer = torch.optim.SGD(dual_net.parameters(),
#                                 lr=SL_LEARNING_RATE,
#                                 momentum=MOMENTUM,
#                                 weight_decay=WEIGHT_DECAY,
#                                 nesterov=True)

#     scaler = torch.cuda.amp.GradScaler()

#     current_lr = SL_LEARNING_RATE

#     for epoch in range(epochs):
#         for data_index, train_data_path in enumerate(train_data_set):
#             plane_data, policy_data, value_data = load_data_set(train_data_path)

#             train_loss = {
#                 "loss": 0.0,
#                 "policy": 0.0,
#                 "value": 0.0,
#             }

#             iteration = 0
#             dual_net.train()
#             epoch_time = time.time()
#             for i in range(0, len(value_data) - batch_size + 1, batch_size):
#                 with torch.cuda.amp.autocast(enabled=True):
#                     plane = torch.tensor(plane_data[i:i+batch_size]).to(device)
#                     policy = torch.tensor(policy_data[i:i+batch_size]).to(device)
#                     value = torch.tensor(value_data[i:i+batch_size]).to(device)

#                     policy_predict, value_predict = dual_net(plane)

#                     dual_net.zero_grad()

#                     policy_loss = calculate_policy_loss(policy_predict, policy)
#                     value_loss = calculate_value_loss(value_predict, value)

#                     loss = (policy_loss + SL_VALUE_WEIGHT * value_loss).mean()

#                 scaler.scale(loss).backward()
#                 scaler.step(optimizer)
#                 scaler.update()

#                 train_loss["loss"] += loss.item()
#                 train_loss["policy"] += policy_loss.mean().item()
#                 train_loss["value"] += value_loss.mean().item()
#                 iteration += 1

#             print_learning_process(train_loss, epoch, data_index, iteration, epoch_time)

#         test_loss = {
#             "loss": 0.0,
#             "policy": 0.0,
#             "value": 0.0,
#         }
#         test_iteration = 0
#         testing_time = time.time()
#         for data_index, test_data_path in enumerate(test_data_set):
#             dual_net.eval()
#             plane_data, policy_data, value_data = load_data_set(test_data_path)
#             with torch.no_grad():
#                 for i in range(0, len(value_data) - batch_size + 1, batch_size):
#                     plane = torch.tensor(plane_data[i:i+batch_size]).to(device)
#                     policy = torch.tensor(policy_data[i:i+batch_size]).to(device)
#                     value = torch.tensor(value_data[i:i+batch_size]).to(device)

#                     policy_predict, value_predict = dual_net(plane)

#                     policy_loss = calculate_policy_loss(policy_predict, policy)
#                     value_loss = calculate_value_loss(value_predict, value)

#                     loss = (policy_loss + SL_VALUE_WEIGHT * value_loss).mean()

#                     test_loss["loss"] += loss.item()
#                     test_loss["policy"] += policy_loss.mean().item()
#                     test_loss["value"] += value_loss.mean().item()
#                     test_iteration += 1

#         print_evaluation_information(test_loss, epoch, test_iteration, testing_time)

#         if epoch in LEARNING_SCHEDULE["learning_rate"]:
#             previous_lr = current_lr
#             for group in optimizer.param_groups:
#                 group["lr"] = LEARNING_SCHEDULE["learning_rate"][epoch]
#             current_lr = LEARNING_SCHEDULE["learning_rate"][epoch]
#             print(f"Epoch {epoch}, learning rate has changed {previous_lr} -> {current_lr}")

#         dual_net_copy = copy.deepcopy(dual_net)
#         save_model(dual_net_copy, os.path.join("model", f"sl-model_{dt_now.strftime('%Y%m%d_%H%M%S')}_Ep:{epoch:0>2}.bin"))























def train_with_gumbel_alphazero_on_cpu(program_dir: str, board_size: int, \
    batch_size: int) -> None: # pylint: disable=R0914,R0915
    """æ•™å¸«ã‚ã‚Šå­¦ç¿’ã‚’å®Ÿè¡Œã—ã€å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹ã€‚CPUã§å®Ÿè¡Œã€‚

    Args:
        program_dir (str): ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€‚
        board_size (int): ç¢ç›¤ã®å¤§ãã•ã€‚
        batch_size (int): ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚ºã€‚
    """
    data_set = sorted(glob.glob(os.path.join(program_dir, "data", "rl_data_*.npz")))

    # å­¦ç¿’å‡¦ç†ã‚’è¡Œã†ãƒ‡ãƒã‚¤ã‚¹ã®è¨­å®š
    device = get_torch_device(use_gpu=False)

    dual_net = DualNet(device=device, board_size=board_size)

    dual_net.to(device)

    optimizer = torch.optim.SGD(dual_net.parameters(),
                                lr=RL_LEARNING_RATE,
                                momentum=MOMENTUM,
                                weight_decay=WEIGHT_DECAY,
                                nesterov=True)
    num_trained_batches = 0

    model_file_path = os.path.join(program_dir, "model", "rl-model.bin")
    if os.path.exists(model_file_path):
        print(f"load {model_file_path}")
        dual_net.load_state_dict(torch.load(model_file_path))

    state_file_path = os.path.join(program_dir, "model", "rl-state.ckpt")
    if os.path.exists(state_file_path):
        print(f"load {state_file_path}")
        checkpoint = torch.load(state_file_path, map_location=device)
        optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
        num_trained_batches = checkpoint["num_trained_batches"]
        for group in optimizer.param_groups:
            group["lr"] = RL_LEARNING_RATE
        print(f"num_trained_batches : {num_trained_batches}")

    for data_index, train_data_path in enumerate(data_set):
        plane_data, policy_data, value_data = load_data_set(train_data_path)
        train_loss = {
            "loss": 0.0,
            "policy": 0.0,
            "value": 0.0,
        }
        iteration = 0
        dual_net.train()
        epoch_time = time.time()
        for i in range(0, len(value_data) - batch_size + 1, batch_size):
            plane = torch.tensor(plane_data[i:i+batch_size]).to(device)
            policy = torch.tensor(policy_data[i:i+batch_size]).to(device)
            value = torch.tensor(value_data[i:i+batch_size]).to(device)

            policy_predict, value_predict = dual_net.forward(plane)

            dual_net.zero_grad()
            policy_loss = calculate_policy_kld_loss(policy_predict, policy)
            value_loss = calculate_value_loss(value_predict, value)

            loss = (policy_loss + RL_VALUE_WEIGHT * value_loss).mean()

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            num_trained_batches += 1

            train_loss["loss"] += loss.item()
            train_loss["policy"] += policy_loss.mean().item()
            train_loss["value"] += value_loss.mean().item()
            iteration += 1

        print_learning_process(train_loss, 0, data_index, iteration, epoch_time)

    save_model(dual_net, model_file_path)

    state = {
        "num_trained_batches": num_trained_batches,
        "optimizer_state_dict": optimizer.state_dict(),
    }
    torch.save(state, state_file_path)





def train_with_gumbel_alphazero_on_gpu(program_dir: str, board_size: int, \
    batch_size: int, rl_num: int, rl_datetime: str, network_name: str="DualNet") -> None: # pylint: disable=R0914,R0915
    """æ•™å¸«ã‚ã‚Šå­¦ç¿’ã‚’å®Ÿè¡Œã—ã€å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹ã€‚GPUã§å®Ÿè¡Œã€‚

    Args:
        program_dir (str): ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€‚
        board_size (int): ç¢ç›¤ã®å¤§ãã•ã€‚
        batch_size (int): ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚ºã€‚
    """

    print(f"ğŸ¾train_with_gumbel_alphazero_on_gpu {dt_now}")###########

    data_set = sorted(glob.glob(os.path.join(program_dir, "data", "rl_data_*.npz")))

    # å­¦ç¿’å‡¦ç†ã‚’è¡Œã†ãƒ‡ãƒã‚¤ã‚¹ã®è¨­å®š
    device = get_torch_device(use_gpu=True)

    if network_name == "DualNet":
        dual_net = DualNet(device=device, board_size=board_size)
        """DualNetã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã€‚å¤šåˆ†ã€ã“ã“ã«ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒ‘ãƒ©ãƒ¡ã‚¿ã¨ã‹å…¥ã£ã¦ã‚‹ã€‚"""
    elif network_name == "DualNet_128_12":
        dual_net = DualNet_128_12(device=device, board_size=board_size)
    elif network_name == "DualNet_256_24":
        dual_net = DualNet_256_24(device=device, board_size=board_size)
    elif network_name == "DualNet_256_24_semeai":
        dual_net = DualNet_256_24_semeai(device=device, board_size=board_size)
    else:
        print(f"ğŸ‘ºnetwork_name: {network_name} is not defined.")
        raise(f"network_name is not defined.")#############
    # dual_net = DualNet(device=device, board_size=board_size)

    dual_net.to(device)

    optimizer = torch.optim.SGD(dual_net.parameters(),
                                lr=RL_LEARNING_RATE,
                                momentum=MOMENTUM,
                                weight_decay=WEIGHT_DECAY,
                                nesterov=True)

    scaler = torch.cuda.amp.GradScaler()

    num_trained_batches = 0

    model_file_path = os.path.join(program_dir, "model", "rl-model.bin")
    if os.path.exists(model_file_path):
        print(f"load {model_file_path}")
        dual_net.load_state_dict(torch.load(model_file_path))

    state_file_path = os.path.join(program_dir, "model", "rl-state.ckpt")
    if os.path.exists(state_file_path):
        print(f"load {state_file_path}")
        checkpoint = torch.load(state_file_path, map_location=device)
        optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
        scaler.load_state_dict(checkpoint["scaler_state_dict"])
        num_trained_batches = checkpoint["num_trained_batches"]
        print(f"num_trained_batches : {num_trained_batches}")

    for data_index, train_data_path in enumerate(data_set):
        print(f"ğŸ¾train_rl_gpu, idx: {data_index}")###########
        plane_data, policy_data, value_data = load_data_set(train_data_path)
        train_loss = {
            "loss": 0.0,
            "policy": 0.0,
            "value": 0.0,
        }
        iteration = 0
        dual_net.train()
        epoch_time = time.time()
        for i in range(0, len(value_data) - batch_size + 1, batch_size):
            with torch.cuda.amp.autocast(enabled=True):
                plane = torch.tensor(plane_data[i:i+batch_size]).to(device)
                policy = torch.tensor(policy_data[i:i+batch_size]).to(device)
                value = torch.tensor(value_data[i:i+batch_size]).to(device)

                policy_predict, value_predict = dual_net.forward(plane)

                dual_net.zero_grad()
                policy_loss = calculate_policy_kld_loss(policy_predict, policy)
                value_loss = calculate_value_loss(value_predict, value)

                loss = (policy_loss + RL_VALUE_WEIGHT * value_loss).mean()

                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()
                num_trained_batches += 1

            train_loss["loss"] += loss.item()
            train_loss["policy"] += policy_loss.mean().item()
            train_loss["value"] += value_loss.mean().item()
            iteration += 1

        print_learning_process(train_loss, 0, data_index, iteration, epoch_time)

    save_model(dual_net, os.path.join(program_dir, "model", f"rl-model_{rl_datetime}_{rl_num}.bin"))
    save_model(dual_net, model_file_path)

    state = {
        "num_trained_batches": num_trained_batches,
        "optimizer_state_dict": optimizer.state_dict(),
        "scaler_state_dict": scaler.state_dict()
    }
    torch.save(state, os.path.join(program_dir, "model", f"rl-state_{rl_datetime}_{rl_num}.ckpt"))
    torch.save(state, state_file_path)
